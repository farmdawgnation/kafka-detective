## Environment Pre-Requisites

Detective works by attaching to two topics. A **test topic** representing the code you'd like to
eventually deploy to production (for many this is a staging environment) and a **reference
environment** that is your known good (for many this is their production environment). Detective
makes a few assumptions about the state of the environment it's going to be attached to.
Specifically those assumptions are:

* The respective environments _should_ be producing the exact same data.
  * The two topics you're monitoring need to have the same number of partitions.
* The environments are in a healthy state when Kafka Detective is first connected. Specifically:
  * The environments are performing at the same speed.
  * The data coming out of the environments matches.
  * The environments are processing the same inputs.

Additionally, to work best Kafka Detective needs a few things to be present in your infrastructure:

* A Graphite Carbon host to feed metrics into.
* Ideally, a Grafana instance (or something similar) dashboarding from those metrics.
* An ElasticSearch instance for Detective to report errors to.
* Ideally, a Kibana instance (or something similar) to analyze failures reported to ES.

If all of the above conditions are true, Kafka Detective should be able to start producing
meaningful output in your environment pretty quickly.
